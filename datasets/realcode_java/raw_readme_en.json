{
  "Task description": "**RealCodeJava** is a benchmark for evaluating the ability of language models to generate function bodies in real-world Java repositories. The benchmark focuses on realistic completions using project-level context and validates correctness through test execution.",
  "Motivation": "This dataset tests how well models can:\n- Generate function bodies based on surrounding code context;\n- Integrate into existing Java projects;\n- Pass real unit tests after insertion.\nThe main evaluation metric is `pass@k`, computed via execution of repository-specific tests inside Docker containers.",
  "Dataset creation": "The benchmark is built from 27 public Java GitHub repositories created in 2024-2025. For each sample, a function is extracted along with its surrounding code (`left_context`, `right_context`) and evaluated based on whether the generated body passes original unit tests. All examples come from real repositories and are reproducibly executable.",
  "Contributors": "Dmitry Vorobiev, Pavel Zadorozhny, Rodion Levichev, Pavel Adamenko, Aidar Valeev, Dmitry Salikhov, Dmitrii Babaev"
}