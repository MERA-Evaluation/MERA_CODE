{"Описание задачи": "Оценка генерации корректного кода на основе некорректного кода и списка ошибок/предупреждений от линтера.", "Мотивация": "\nБенчмарк направлен на выявление способностей моделей для генерации и исправление кода на основе ошибок от линтера.\nДатасет ориентирован на:  \n- Кодогенерирующие модели (например, Codex, CodeLlama, StarCoder, GPT-4), способные исправлять код на основе линтерных ошибок.  \n- Модели, специализирующиеся на рефакторинге и исправлении кода (например, DeepSeek-R1, CodeT5).\n- Мультимодальные модели, если они умеют работать с кодом и текстовыми инструкциями.  \nНе подходит для:  \n- Моделей без понимания кода (например, чисто текстовые LLM без дообучения на code).  \n- Моделей, не поддерживающих Python.  \n- Моделей, тонко настроенных на решение задачи FIM(Fill-in-the-middle).\n\nРезультаты оценки могут быть полезны:  \n- Разработчикам инструментов для автоматического рефакторинга кода (например, IDE-плагины);  \n- Исследователям в области генерации и исправления кода;  \n- Инженерам, оценивающих качество code generation моделей.  \n\nРезультаты бенчмарка покажут насколько хорошо модель справляется с исправлением кода по линтерным ошибкам, что означаеи, что модель \nможет быть полезна для:  \n  - автоматического исправления кода,  \n  - улучшения качества кода в IDE,  \n  - обучения новичков писать \"чистый\" код.  \nЕсли модель плохо справляется, значит, она либо не понимает линтерные ошибки, либо не умеет правильно применять исправления. \n\nВ бенчмарке оценивается:  \n1. Понимание линтерных ошибок – способность правильно интерпретировать сообщения типа E111, E231 и т.д.  \n2. Корректный рефакторинг кода – умение вносить исправления, сохраняя логику программы.  \n3. Следование стилю кода (PEP 8) – правильные отступы, пробелы, форматирование.  \n4. Контекстное понимание кода – модель не должна ломать логику при исправлении стиля.\nЛинтерные ошибки – частый случай в разработке, и автоматическое исправление экономит время.\nЕсли модель не умеет исправлять простые стилевые ошибки, она вряд ли справится с более сложными задачами рефакторинга.  \n\nДатасет содержит:  \ncode – исходный код с ошибками;\nfeedback – список ошибок от линтера;  \ninstruction – явное указание исправить код на основе feedback; \ncanonical_code – эталонный код\nЯвное указание ошибок позволяет оценить именно способность модели исправлять код по линтеру, а не \"угадывать\" ошибки.  \nКаноническое решение (canonical_code) дает четкий ground truth для оценки.\nИнструкция явно указывает задачу, чтобы модель не отклонялась от цели.\n\nЕсли модель исправляет код в соответствии с feedback и линтер не обнаруживает ошибок после проверки результатов генерации - значит результат корректен.\nЕсли ошибки сохраняются или появляются новые - модель не решает поставленную задачу.\n\nМетрикой является pass@k, определяемая на результатах успешности проверки линтером относительно общего объема датасета.\n", "Создание датасета": "\nДля создания качественного датасета, где модель должна исправлять код на основе линтерных ошибок, необходимо:  \n1. В качестве исходного датасета было выбрано подмножество из датасета mbpp.  \n2. Для каждого примера кода был запущен линтер flake8 для выявления ошибок.  \n3. В итоговый датасет попали только те примеры, которые имели не менее 1 ошибки.\n4. Для получения канонических решений код был вручную исправлен экспертами и повторно проверен линтером.  \n5. Результаты проверки линтером сохранены в виде строк с кодом ошибки и ее описанием от линтера и сохранены в поле feedback (например, \n\"E111 indentation is not a multiple of four, E231 missing whitespace after ','\")\n", "Human baseline": "Методология human_baseline в разработке.", "Авторы": "Викулов В.А., Быков А.В., Пихтовников К.Е."}