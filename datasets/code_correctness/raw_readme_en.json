{
  "Task description": "Evaluation of the correctness of the written code for Python, Java and Go. Correctness means the absent of any errors including SyntaxError, Runtime Error etc. and the successful tests passing as well.",
  "Motivation": "It is assumed that during the training process the model learns not only to generate the code and solve different tasks but also learns to process and analyze the code, e.g. to detect whether the code is correct, contains any errors etc. This dataset was developed to automatically evaluate such ability. Any model, which assess the code correctness, should be limited with a given context. To define whether the code is successfully executed, we collected such pairs {focal_code - test_code}, which do not contain the imports from the other files of the projects. Also we kept only the files which do not contain any assets usage, e.g. loading data from files.",
  "Dataset creation": "The dataset creation includes the following stages:\n\n1) Automatic retrieval, parsing and processing of open-source repositories from GitHub based on the number of stars, novelty (date of the latest commits) and execution (check whether the project is built successfully and focal and test files are executed successfully);\n2) The collection of dataset samples from the repositories data in the following format: focal file source code | test file source code;\n3) The creation of two subsets: original (the samples contain the original test files) and generated (the samples contain the generated test cases by LLM);\n4) The samples were tagged with the following features: the number of lines in test case, the number of lines in the focal file, syntax correctness, import types etc.;\n5) The samples were filtered out to keep only the samples for which the task of correctness determining may be solved without additional inputs.\n6) The final version of the dataset was formed from the filtered data. ",
  "Contributors": ""
}